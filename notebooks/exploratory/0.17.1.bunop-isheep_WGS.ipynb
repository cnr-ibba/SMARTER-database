{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193de060-b877-41be-a31b-d7fdf64441e3",
   "metadata": {},
   "source": [
    "# ISHEEP WGS DATASET\n",
    "\n",
    "This is an attempt to collect SNPs from [isheep WGS dataset](https://ngdc.cncb.ac.cn/isheep/download) and track them in to smarter database. There absolutely no info regarding *probeset IDs*, so the only way to collect SNPs from this dataset relies on position on *OAR4*. Data is divided by chromosomes and where downloaded from [isheep WGS ftp folder](ftp://download.big.ac.cn/isheep/SNP).\n",
    "\n",
    "## Data preparation\n",
    "\n",
    "Files were compressed using the standard `gzip` utility. Unpack all files and compress them using `bgzip`, then index with `tabix`:\n",
    "\n",
    "```bash\n",
    "for compressed in $(ls *.vcf.gz); do echo \"Processing \" $compressed; vcf=\"${compressed%.*}\"; bgzip -d --stdout $compressed | bgzip -@24 --compress-level 9 --stdout > $vcf.bgzip ; done\n",
    "for compressed in $(ls *.bgzip); do echo \"Processing \" $compressed; bgzip --test $compressed ; done\n",
    "for compressed in $(ls *.bgzip); do echo \"Processing \" $compressed; vcf=\"${compressed%.*}.gz\" ; mv $compressed $vcf ; tabix $vcf ; done\n",
    "```\n",
    "\n",
    "Now I can try to extract my probes relying on positions and `tabix`. The point is that I could have more probe on the same position, so I can't assign a unique `VariantSheep.name` to a certain SNP; Moreover positions need to be checked against `OAR4` before querying VCF. For the moment, I will try to extract the information I need relying on the data I have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd4ee7c5-0390-422e-853e-7dcd8cd69e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from mongoengine.errors import DoesNotExist, MultipleObjectsReturned\n",
    "\n",
    "from src.features.smarterdb import global_connection, VariantSheep\n",
    "from src.features.utils import get_interim_dir, get_project_dir\n",
    "from src.features.plinkio import BinaryPlinkIO, CodingException\n",
    "from src.data.common import WORKING_ASSEMBLIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e30661-e393-4b83-ae6b-e34cbcada3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = global_connection()\n",
    "OAR4 = WORKING_ASSEMBLIES[\"OAR4\"]\n",
    "OAR3 = WORKING_ASSEMBLIES[\"OAR3\"]\n",
    "logger = logging.getLogger('src.features.plinkio')\n",
    "logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84d558-e454-4473-ad35-1b30aa741f07",
   "metadata": {},
   "source": [
    "## Creating the regions file\n",
    "\n",
    "As described by the `tabix` documentation, I can collect samples by region. Chromosome and position in a *tab separated* file is enough. I have a VCF for each chromosome, so I need to collect data by chromosomes. I could have the same position more times in this data file (since different probeset could be present more times): i need to extract the same record more than once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e1d064-0a62-48f8-8583-9a2a12eb992e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ba49fa56ce149bf90bbb3f38cec7576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chromosomes = [str(chrom) for chrom in range(1, 27)] + [\"X\"]\n",
    "\n",
    "for chrom in tqdm(chromosomes):\n",
    "    regions_filename = get_interim_dir() / f\"chr{chrom}_regions.tsv\"\n",
    "    \n",
    "    if regions_filename.exists():\n",
    "        # save some time, skip evaluation\n",
    "        continue\n",
    "        \n",
    "    condition = OAR4._asdict()\n",
    "    condition['chrom'] = chrom\n",
    "    variants = VariantSheep.objects.filter(\n",
    "        locations__match=condition\n",
    "    ).fields(\n",
    "        elemMatch__locations=OAR4._asdict(),\n",
    "        name=1,\n",
    "        rs_id=1\n",
    "    )\n",
    "    \n",
    "    locations = set()\n",
    "    \n",
    "    for variant in variants:\n",
    "        location = (variant.locations[0].chrom, variant.locations[0].position)\n",
    "        \n",
    "        if location not in locations:\n",
    "            locations.add(location)\n",
    "            \n",
    "    locations = sorted(list(locations), key=lambda location: location[1])\n",
    "    \n",
    "    with open(regions_filename, \"w\") as handle:\n",
    "        writer = csv.writer(handle, delimiter=\"\\t\", lineterminator=\"\\n\")\n",
    "        for location in locations:\n",
    "            writer.writerow(location)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce87705-f900-4d1f-a8dc-ef4c127ffaa9",
   "metadata": {},
   "source": [
    "## Extract variants from VCF\n",
    "\n",
    "It's time to extract the sheep smarter variants from the VCF files. Then merge all files into one VCF:\n",
    "\n",
    "```bash\n",
    "for i in $(seq 1 26); do echo \"tabix -h -R chr$i\\_regions.tsv output_chr$i.snp.filtered.vcf.gz | bgzip --compress-level 9 --stdout > smarter_chr$i\\_regions.vcf.gz; tabix smarter_chr$i\\_regions.vcf.gz\" >> commands.sh ; done\n",
    "echo \"tabix -h -R chrX\\_regions.tsv output_chrX.snp.filtered.vcf.gz | bgzip --compress-level 9 --stdout > smarter_chrX\\_regions.vcf.gz; tabix smarter_chrX\\_regions.vcf.gz\" >> commands.sh\n",
    "parallel --jobs 12 < commands.sh\n",
    "vcf-concat smarter_chr*.vcf.gz | bgzip -@12 --stdout > WGS-all/WGS-all.smarter.vcf.gz\n",
    "tabix WGS-all/WGS-all.smarter.vcf.gz\n",
    "plink --chr-set 26 --allow-extra-chr --vcf WGS-all/WGS-all.smarter.vcf.gz --make-bed --double-id --out WGS-all/WGS-all.smarter\n",
    "```\n",
    "\n",
    "Please note that in the final plink file `WGS-all.smarter.bim` SNPs have no name: this need to be fixed with the `VariantSheep.name` field in order to be merged with the SMARTER dataset. I can define a custom method to search variants by position (not by name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41c507b9-b22c-48b6-a8f4-e4f0a4545e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBinaryPlinkIO(BinaryPlinkIO):\n",
    "    def process_pedfile(self, coding=\"top\"):\n",
    "        for line in tqdm(self.read_pedfile(), total=len(self.plink_file.get_samples())):\n",
    "            _ = self._process_genotypes(line, coding)\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def is_top(self):\n",
    "        try:\n",
    "            return self.process_pedfile(coding='top')\n",
    "        \n",
    "        except CodingException:\n",
    "            return False\n",
    "    \n",
    "    def is_forward(self):\n",
    "        try:\n",
    "            return self.process_pedfile(coding='forward')\n",
    "        \n",
    "        except CodingException:\n",
    "            return False\n",
    "        \n",
    "    def fetch_coordinates_by_positions(self, src_assembly: dict, dst_assembly: dict):\n",
    "        # reset meta informations\n",
    "        self.locations = list()\n",
    "        self.filtered = set()\n",
    "        self.variants_name = list()\n",
    "\n",
    "        # helper function\n",
    "        def skip_index(idx):\n",
    "            # skip this variant (even in ped)\n",
    "            self.filtered.add(idx)\n",
    "\n",
    "            # need to add an empty value in locations (or my indexes\n",
    "            # won't work properly). The same for variants name\n",
    "            self.locations.append(None)\n",
    "            self.variants_name.append(None)\n",
    "        \n",
    "        for idx, record in enumerate(tqdm(self.mapdata, mininterval=2)):\n",
    "            location = src_assembly.copy()\n",
    "            location[\"chrom\"] = record.chrom\n",
    "            location[\"position\"] = record.position\n",
    "            \n",
    "            # attempt to fix-up 27 chrom\n",
    "            if int(location[\"chrom\"]) == 27:\n",
    "                location[\"chrom\"] = \"X\"\n",
    "        \n",
    "            try:\n",
    "                variant = self.VariantSpecies.objects(\n",
    "                    locations__match=location,\n",
    "                ).fields(\n",
    "                    elemMatch__locations=dst_assembly,\n",
    "                    name=1,\n",
    "                    rs_id=1\n",
    "                ).get()\n",
    "            \n",
    "            except DoesNotExist as e:\n",
    "                logger.warning(\n",
    "                    f\"Couldn't find {record.chrom}:{record.position} in {src_assembly}\"\n",
    "                    f\" assembly: {e}\")\n",
    "\n",
    "                skip_index(idx)\n",
    "\n",
    "                # don't check location for missing SNP\n",
    "                continue\n",
    "                \n",
    "            except MultipleObjectsReturned as e:\n",
    "                # tecnically, I could return the first item I found in my database\n",
    "                # skip, for the moment\n",
    "                logger.debug(\n",
    "                    f\"Got multiple {record.chrom}:{record.position} in {src_assembly}\"\n",
    "                    f\" assembly: {e}\")\n",
    "\n",
    "                skip_index(idx)\n",
    "\n",
    "                # don't check location for missing SNP\n",
    "                continue\n",
    "                \n",
    "            # using projection I will have only one location if I could\n",
    "            # find a SNP\n",
    "            location = variant.locations[0]\n",
    "\n",
    "            # track data for this location\n",
    "            self.locations.append(location)\n",
    "\n",
    "            # track variant.name read from database (useful when searching\n",
    "            # using probeset_id)\n",
    "            self.variants_name.append(variant.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bbcbde-252b-4e48-b06b-0f9ec463dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7c1431ff72492f848ef0ab773187cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/602009 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prefix = str(get_project_dir() / \"data/external/SHE/ISHEEP/WGS-all/WGS-all.smarter\")\n",
    "plinkio = CustomBinaryPlinkIO(prefix= prefix, species=\"Sheep\", chip_name=\"IlluminaOvineSNP50\")\n",
    "plinkio.read_mapfile()\n",
    "plinkio.fetch_coordinates_by_positions(src_assembly=OAR4._asdict(), dst_assembly=OAR3._asdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fef0f55-c102-41fe-b355-ed9858b9db41",
   "metadata": {},
   "source": [
    "Is this file in illumina top?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea56a4e0-1b18-4fcb-a5fe-3a68b1f703ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a41c3e60e649de888b5f2f80c25c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error for SNP 2:.: T/T <> A/C\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plinkio.is_top()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f3ca55-37d0-441f-9ae8-9cb757bfa706",
   "metadata": {},
   "source": [
    "Ok, is this in forward coordinates (as supposed to be for a VCF?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26676ef0-c0ff-482a-8472-33146f691f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841970449d26498b9a4d96c3c8234a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error for SNP 59:.: T/T <> A/G\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plinkio.is_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4749d9-f73a-4b99-afd3-340c1c49010c",
   "metadata": {},
   "source": [
    "This is unexpected: why this genotypes can't be converted? Get some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc952f81-ac10-42bd-bd45-79e66262f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNP 59(['T', 'T']):DU281551_498.1 is not in forward coordinates)\n",
      "SNP 59(['T', 'T']):DU281551_498.1 is not in top coordinates)\n"
     ]
    }
   ],
   "source": [
    "def get_info_snp(idx):\n",
    "    sample_genotypes = next(plinkio.read_pedfile())\n",
    "\n",
    "    snp = plinkio.mapdata[idx]\n",
    "    a1 = sample_genotypes[6+idx*2]\n",
    "    a2 = sample_genotypes[6+idx*2+1]\n",
    "    genotype = [a1, a2]\n",
    "    location = plinkio.locations[idx]\n",
    "    name = plinkio.variants_name[idx]\n",
    "\n",
    "    if not location.is_forward(genotype):\n",
    "        print(f\"SNP {idx}({genotype}):{name} is not in forward coordinates)\")\n",
    "    if not location.is_top(genotype):\n",
    "        print(f\"SNP {idx}({genotype}):{name} is not in top coordinates)\")\n",
    "        \n",
    "get_info_snp(59)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454dd39d-ba4e-49e2-8974-f1a628f1d0cf",
   "metadata": {},
   "source": [
    "This SNP in particoular seems to have issue: I know from other sources that it should be C/T in forward, however is stored in A/G in snpchimp and I can't use any other sources to derive the correct genotypes. So let's drop this SNPs and similar SNPs from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20626a04-d4fc-43b0-b8d0-0c835798f346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1504 SNPs are not in forward and were removed\n"
     ]
    }
   ],
   "source": [
    "def drop_variants(plinkio):\n",
    "    counter = 0\n",
    "    \n",
    "    for idx, locus in enumerate(plinkio.plink_file.get_loci()):\n",
    "        location = plinkio.locations[idx]\n",
    "        \n",
    "        if not location:\n",
    "            # some SNPs have already been removed\n",
    "            continue\n",
    "        \n",
    "        genotype = locus.allele1, locus.allele2\n",
    "        \n",
    "        # remove the non-forward variants\n",
    "        if not location.is_forward(genotype):\n",
    "            # this SNPs should be removed\n",
    "            counter += 1\n",
    "            \n",
    "            # add SNP to filtered set\n",
    "            plinkio.filtered.add(idx)\n",
    "\n",
    "    \n",
    "    print(f\"{counter} SNPs are not in forward and were removed\")\n",
    "    \n",
    "drop_variants(plinkio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9548070-71e3-4d22-a088-62652722786e",
   "metadata": {},
   "source": [
    "Test for forward again (this time I suppose it will work without problems):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123e97c4-a8d9-4d96-bdfa-33b39d6e3ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e25f9193d0c46bdba66993a78b220c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plinkio.is_forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75d301-37b9-477f-bb03-1f02f2b2a83d",
   "metadata": {},
   "source": [
    "What about try allelic SNPs? consider 1:811144 which is C->T,G: only two alleles are considered. Sample *0624D_L2_321* which should be *G/G* will be set as missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b121c8ff-09a5-45f7-adee-65ff56097d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0624D_L2_321 0624D_L2_321 -9 -9 ('0', '0')\n"
     ]
    }
   ],
   "source": [
    "def convert(genotype, locus):\n",
    "    # in binary format, allele2 is REF allele1 ALT\n",
    "    if genotype == 0:\n",
    "        return locus.allele1, locus.allele1\n",
    "    elif genotype == 1:\n",
    "        return locus.allele2, locus.allele1\n",
    "    elif genotype == 2:\n",
    "        return locus.allele2, locus.allele2\n",
    "    elif genotype == 3:\n",
    "        return \"0\", \"0\"\n",
    "    else:\n",
    "        raise CodingException(\"Genotype %s Not supported\" % genotype)\n",
    "\n",
    "for locus, row in zip( plinkio.plink_file.get_loci(), plinkio.plink_file ):\n",
    "    if locus.chromosome == \"1\" and locus.bp_position == 811144:\n",
    "        for sample, genotype in zip( plinkio.plink_file.get_samples(), row ):\n",
    "            if sample.iid == \"0624D_L2_321\":\n",
    "                print(sample, convert(genotype, locus))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4300005-daab-4fdb-a137-c2b85f0094bc",
   "metadata": {},
   "source": [
    "Which genotypes will be chosen? I suppose the most frequent, but I need to ensure this (however, since I remove the non forward snp, those SNPs will be filtered out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872e42b8-43cf-4f10-ac68-9e4ff4305a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
