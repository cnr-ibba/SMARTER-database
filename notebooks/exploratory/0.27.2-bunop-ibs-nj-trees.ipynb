{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine mislabelling using NJ tree and IBS distance matrix\n",
    "\n",
    "In this example, we will demonstrate how to determine mislabelling using the Neighbor \n",
    "Joining (NJ) tree and a random distance matrix. We will use the following steps \n",
    "to determine mislabelling:\n",
    "\n",
    "## Step 1: Build the NJ Tree from the IBS Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Bio import Phylo\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor, DistanceMatrix\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Example IBS distance matrix (replace with actual data)\n",
    "# Assuming 'distance_df' is your IBS-based distance matrix with individuals in rows/columns\n",
    "# distance_df = pd.read_csv(\"ibs_distance_matrix.csv\", index_col=0)\n",
    "# In this example, we simulate a distance matrix\n",
    "samples = [f'Sample {i}' for i in range(10)]\n",
    "distance_matrix = np.random.rand(10, 10)\n",
    "np.fill_diagonal(distance_matrix, 0)  # Set diagonal to 0 (distance to self is zero)\n",
    "\n",
    "# Convert distance matrix to lower triangular format\n",
    "lower_triangle_matrix = []\n",
    "for i in range(len(samples)):\n",
    "    lower_triangle_matrix.append(distance_matrix[i, :i+1].tolist())  # Take lower triangular part\n",
    "\n",
    "# Convert distance matrix into BioPython DistanceMatrix\n",
    "matrix = DistanceMatrix(names=samples, matrix=lower_triangle_matrix)\n",
    "\n",
    "# Build NJ tree\n",
    "constructor = DistanceTreeConstructor()\n",
    "nj_tree = constructor.nj(matrix)\n",
    "\n",
    "# Visualize the tree (optional)\n",
    "Phylo.draw_ascii(nj_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Group Individuals Based on NJ Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traverse the NJ tree and extract clusters based on total pairwise distance within clades\n",
    "def extract_clusters_by_total_distance(tree, distance_threshold):\n",
    "    clusters = []\n",
    "\n",
    "    # Traverse the internal nodes of the tree\n",
    "    for clade in tree.get_nonterminals():\n",
    "        # Get all terminal nodes (samples) under this clade\n",
    "        terminals = clade.get_terminals()\n",
    "        if len(terminals) < 2:\n",
    "            continue  # Ignore clades with less than two terminals\n",
    "\n",
    "        # Calculate the maximum pairwise distance between samples in this clade\n",
    "        max_pairwise_distance = 0\n",
    "        for term1 in terminals:\n",
    "            for term2 in terminals:\n",
    "                distance = tree.distance(term1, term2)\n",
    "                if distance > max_pairwise_distance:\n",
    "                    max_pairwise_distance = distance\n",
    "\n",
    "        # If the maximum pairwise distance is below the threshold, consider it a cluster\n",
    "        if max_pairwise_distance <= distance_threshold:\n",
    "            cluster_samples = [term.name for term in terminals]\n",
    "            clusters.append(cluster_samples)\n",
    "\n",
    "    # Remove clusters that are subsets of other clusters\n",
    "    unique_clusters = remove_subset_clusters(clusters)\n",
    "\n",
    "    return unique_clusters\n",
    "\n",
    "# Helper function to remove clusters that are subsets of other clusters\n",
    "def remove_subset_clusters(clusters):\n",
    "    clusters = sorted(clusters, key=len, reverse=True)  # Sort clusters by size (largest first)\n",
    "    unique_clusters = []\n",
    "\n",
    "    for cluster in clusters:\n",
    "        is_subset = False\n",
    "        for unique_cluster in unique_clusters:\n",
    "            if set(cluster).issubset(set(unique_cluster)):\n",
    "                is_subset = True\n",
    "                break\n",
    "        if not is_subset:\n",
    "            unique_clusters.append(cluster)\n",
    "\n",
    "    return unique_clusters\n",
    "\n",
    "# Example usage:\n",
    "distance_threshold = 0.3  # Define your threshold for maximum pairwise distance within clusters\n",
    "clusters = extract_clusters_by_total_distance(nj_tree, distance_threshold)\n",
    "print(\"Unique Clusters (after removing subsets):\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phylo.draw_ascii(nj_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Compare Genetic Clusters with Declared Breed Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'assignment_df' contains 'sample' and 'breed' information\n",
    "assignment_df = pd.DataFrame({\n",
    "    'sample': samples,\n",
    "    'breed': ['Breed A', 'Breed A', 'Breed B', 'Breed B', 'Breed A', 'Breed A', 'Breed C', 'Breed B', 'Breed C', 'Breed C']\n",
    "})\n",
    "\n",
    "# Create a new column for cluster IDs\n",
    "cluster_assignments = []\n",
    "\n",
    "# Loop through each sample in the assignment_df\n",
    "for sample in assignment_df['sample']:\n",
    "    assigned_cluster = None\n",
    "    # Check which cluster the sample belongs to\n",
    "    for cluster_id, cluster in enumerate(clusters, 1):  # Cluster IDs start from 1\n",
    "        if sample in cluster:\n",
    "            assigned_cluster = cluster_id\n",
    "            break\n",
    "    cluster_assignments.append(assigned_cluster)\n",
    "\n",
    "# Add the cluster information as a new column\n",
    "assignment_df['detected_cluster'] = cluster_assignments\n",
    "\n",
    "# Display the updated assignment_df\n",
    "assignment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to label clusters with the most common (mode) breed and detect mislabelled samples\n",
    "def check_and_label_clusters(clusters, assignment_df):\n",
    "    mislabelled = []\n",
    "    cluster_labels = {}\n",
    "\n",
    "    for cluster_id, cluster in enumerate(clusters, 1):\n",
    "        # Get the declared breeds for all samples in the cluster\n",
    "        cluster_breeds = assignment_df[assignment_df['sample'].isin(cluster)]['breed']\n",
    "\n",
    "        # Find the most common (mode) breed using value_counts()\n",
    "        mode_breed = cluster_breeds.value_counts().idxmax()  # The most frequent breed in the cluster\n",
    "\n",
    "        # Label the cluster with the mode breed\n",
    "        cluster_labels[cluster_id] = mode_breed\n",
    "\n",
    "        # Flag individuals whose breed doesn't match the mode\n",
    "        for sample in cluster:\n",
    "            declared_breed = assignment_df[assignment_df['sample'] == sample]['breed'].values[0]\n",
    "            if declared_breed != mode_breed:\n",
    "                mislabelled.append(sample)\n",
    "\n",
    "    return mislabelled, cluster_labels\n",
    "\n",
    "# Function to update assignment_df with the cluster labels\n",
    "def update_assignment_with_clusters(assignment_df, clusters, cluster_labels):\n",
    "    # Create a new column for the cluster labels\n",
    "    assignment_df['cluster_label'] = None  # Initialize the column\n",
    "\n",
    "    # Assign cluster labels to the corresponding samples\n",
    "    for cluster_id, cluster in enumerate(clusters, 1):\n",
    "        mode_breed = cluster_labels[cluster_id]\n",
    "        assignment_df.loc[assignment_df['sample'].isin(cluster), 'cluster_label'] = mode_breed\n",
    "\n",
    "    return assignment_df\n",
    "\n",
    "# Find mislabelled individuals and assign cluster labels\n",
    "mislabelled_breeds, cluster_labels = check_and_label_clusters(clusters, assignment_df)\n",
    "\n",
    "# Update the DataFrame to store the assigned cluster labels\n",
    "updated_assignment_df = update_assignment_with_clusters(assignment_df, clusters, cluster_labels)\n",
    "\n",
    "# Output\n",
    "print(\"Mislabelled or crossbreed samples:\", mislabelled_breeds)\n",
    "print(\"Cluster labels (mode breed):\", cluster_labels)\n",
    "print(\"Updated DataFrame with Cluster Labels:\")\n",
    "updated_assignment_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SMARTER-database",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
